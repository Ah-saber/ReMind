# Abstract

无人机检测和跟踪技术需求，尤其实时系统需要有高鲁棒性，敏感性，高效性，计算量小

提出一种基于安装在无人机平台的摄像机奥精度和计算效率的无人机to无人机的检测跟踪

收集创建了一个数据集

# Intro

雷达等传感器有重量与功率的要求，不适用于小型无人机，无源光学传感器更加合适

**自主规避系统** 自动化无人机规避系统，需要敏感高效的算法

尽管卷积神经网络应用，行人，汽车检测等算法商用，但是无人机的检测和跟踪面临许多挑战

相机平台和检测物体都是高速移动，摄像机会采集到不同的运动轮廓，所以必须要有对非平面和复杂背景运动的鲁棒性，同时无人机外观可大可小，像素可能被外物遮挡，外观本身可能不是鲁棒检测的可靠特征

另外数据少，获取难

已经有一些作品用于检测无人机
- Rozantsev 运动补偿，是运动物体处于中心位置，再用深度学习检测；采用滑动窗口检测，有效但需要无人机相对较近，计算量大
- Saribas YOLOv3，结合和核相关滤波(kernelized correlation filter KCF)，需要外观做主要特征，计算量大

论文方法是在作者相关论文基础上的创新，该算法使用移动目标检测器和目标跟踪器组成模块化结构，在实现高精度同时最大限度减少计算；同时将动作和外观整合到分类过程中，提高检测概率，减少误报

同时给出一个数据集

# Conclusion

目标检测利用稀疏估计的全局视角变换精确地从后续帧中去除背景

同时发现通过Adaboost结合外观和运动分类器的混合分类器可以提高召回率和精度

卡尔曼跟踪可以在不增加计算量下进一步提高精度

算法足够高效，可在ARM板上几乎实时运行，尽管分辨率低

# Algorithm

算法分为目标检测器和目标跟踪器，目标检测器通过检测与无人机一致的局部运动和外观区域，选定候选点，利用光流和卡尔曼跟踪相结合的方法恢复检测到的目标的准确连续跟踪，即使杂波或漏检情况下

## 算法概述

运动目标检测器：
- 估计稀疏分布点处的光流
- 通过透视变换将点拟合到背景运动模型中估计全局运动
- 计算背景减影图像
- 提取显著点
- 混合分类器通过外观和愚弄的那个信息从显著点中选择候选点

目标跟踪器：
- 从候选点开始跟踪
- 使用光流传播流点，使用混合分类器修剪不准确的传播
- 卡尔曼跟踪提高检测到的无人机的时间一致性

![[Pasted image 20240904204635.png]]


## 目标检测器

稀疏分布点的光流估计：
- 估计分布在图像上的系数特征点集光流，首先在前一图像帧Xn-1上均匀分布的随机点上选择K个特征点
- 对每个特征点在Xn-1帧中使用Shi-Tomasi角点检测器的标准计算显著性
- 丢弃指定距离D内有更显著点的点，最后得到一组帧Xn-1的特征点，每个确定帧中离散像素位置的2d的向量
- 估计每个特征点处的前向和后向光流矢量，使用Lucas-Kanade方法求解最小二乘问题估计前向光流矢量到亚像素精度
- 以此计算帧Xn中相应的特征点
- 也可以计算反向光流矢量
- 理论上正反向光流矢量应该相同，所以丢弃二者相减大于某个阈值的点












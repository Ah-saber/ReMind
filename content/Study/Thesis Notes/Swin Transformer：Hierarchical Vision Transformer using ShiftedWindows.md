ICCV 21 最佳论文

使用移动窗口的层级Vision Transformer

# Abstract

ViT指出Transformer的可用性，但是无法证明其普适性，Swin Transformer则证明了可以使用Transformer做所有视觉任务的**骨干网络**

存在一些挑战：
- **图像尺寸** 图像的语义信息大大小小，相同语义的车，行人在一张街景图片中可大可小，这是在NLP领域并不存在的问题
- **图像分辨率问题**  传统方法中像素决定Transformer的输入，而像素信息很大，计算量巨大无法在CV领域应用

**层级式Transformer**  通过移动窗口实现
- 更好的计算效率，自注意力在一个窗口内计算
- 层级区分，上下层之间有跨层次的交互（cross-windows），使得计算灵活，复杂度随图像线性增长而不是平方极增长

存在分层次的特征，在下游任务有不错的应用

# Intro

### 模型结构

**层级结构** 用层级结构来理解，ViT是进行以此16x下采样之后保持不变的层级变换，而且其自注意力始终是在全局进行计算的

其复杂度是图像尺寸平方级别的增长，且对多尺寸特征的提取比较一般

窗口式的设计借鉴卷积设计，固定窗口大小，自注意力计算局限在窗口内，复杂度一定

图片尺寸变大，窗口大小不变，用窗口为单位，其数量与尺寸成线性增长关系而非平方级别增长关系，窗口内计算复杂度确定，所以整体的计算复杂度随尺寸为线性变化

同时利用了Locality的 [[归纳偏置(inductive biases)]]，用local的自注意力理论上来说式足够的

同时参照池化层设计patch merging层，合并小patch，增大感受野，提取多尺度特征

![Pasted image 20240807181300](https://raw.githubusercontent.com/Ah-saber/MyPic/main/Pasted%20image%2020240807181300.png)

这样一来，提取到多尺寸特征的Swin Transformer就可以连接多种网络，利用这部分特征实现不同的任务

# 方法

## 具体设计

### 移动窗口

如果单单是固定的窗口，那么由于窗口是固定的，在其内部做自注意力就无法注意到不同窗口內部信息，所以需要有窗口移动的操作

具体是在某一层将图片等分为多个窗口，每个窗口包含49个patch(4x4)，往右下角移动这些窗口，使得窗口部分出去，新的窗口部分进来，通过这个移动来让窗口之间产生交互

![[Pasted image 20240807212440.png]]

这就是隔层之间的cross-window connection

